import streamlit as st
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
import joblib

# -------------------------------
# PARAMÃˆTRES
# -------------------------------
IMAGE_SIZE = (100, 100)
DATA_DIR = "originalimages_part2"

# VÃ©rifier si le dossier existe
if not os.path.exists(DATA_DIR):
    st.error(f"âŒ Le dossier '{DATA_DIR}' n'existe pas!")
    st.info(f"ğŸ“ Veuillez crÃ©er le dossier '{DATA_DIR}' et y mettre vos images")
    st.stop()

try:
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
except Exception as e:
    st.error(f"âŒ Erreur chargement Haar Cascade: {e}")
    st.stop()

def extraire_visage(img):
    """Extrait et redimensionne le visage d'une image"""
    try:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        if len(faces) == 0:
            return None

        x, y, w, h = faces[0]
        face = gray[y:y+h, x:x+w]
        face = cv2.resize(face, IMAGE_SIZE)
        return face
    except Exception as e:
        st.error(f"Erreur extraction visage: {e}")
        return None

# -------------------------------
# CHARGEMENT DES DONNÃ‰ES
# -------------------------------
@st.cache_data
def charger_donnees(path):
    """Charge les donnÃ©es avec cache pour performances"""
    images, labels = [], []
    
    if not os.path.exists(path):
        return np.array([]), np.array([])
        
    files = [f for f in os.listdir(path) if f.lower().endswith((".jpg", ".png", ".jpeg"))]
    
    if len(files) == 0:
        st.error("âŒ Aucune image trouvÃ©e dans le dossier!")
        return np.array([]), np.array([])
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, file in enumerate(files):
        try:
            img_path = os.path.join(path, file)
            img = cv2.imread(img_path)
            
            if img is None:
                continue
                
            face = extraire_visage(img)
            if face is None:
                continue

            flat = face.flatten()
            
            # Extraction de l'ID personne
            if '-' in file:
                person_id = int(file.split("-")[0])
            else:
                # Alternative pour autres formats de nommage
                person_id = int(''.join(filter(str.isdigit, file)) or 1)
            
            images.append(flat)
            labels.append(person_id - 1)
            
            # Mise Ã  jour progression
            if i % 10 == 0:
                progress = (i + 1) / len(files)
                progress_bar.progress(progress)
                status_text.text(f"ğŸ“ Chargement... {i+1}/{len(files)} images")
                
        except Exception as e:
            st.warning(f"âš ï¸ Erreur avec {file}: {e}")
            continue
    
    progress_bar.empty()
    status_text.empty()
    
    return np.array(images), np.array(labels)

# -------------------------------
# INTERFACE STREAMLIT
# -------------------------------
st.set_page_config(page_title="Reconnaissance Faciale PCA + LDA + ML", layout="wide")
st.title("ğŸ§  Reconnaissance Faciale : PCA + LDA + Machine Learning")

# Sidebar pour paramÃ¨tres
st.sidebar.header("âš™ï¸ ParamÃ¨tres du modÃ¨le")
model_choice = st.sidebar.selectbox(
    "Choix du modÃ¨le",
    ["Random Forest", "SVM", "MLP (Neural Network)"],
    index=0
)

# ParamÃ¨tres selon le modÃ¨le
if model_choice == "Random Forest":
    n_estimators = st.sidebar.slider("Nombre d'arbres", 50, 300, 100)
    max_depth = st.sidebar.slider("Profondeur max", 5, 50, 20)
elif model_choice == "SVM":
    kernel_type = st.sidebar.selectbox("Kernel", ["rbf", "linear", "poly"])
    C_value = st.sidebar.slider("ParamÃ¨tre C", 0.1, 10.0, 1.0)
else:  # MLP
    hidden_layers = st.sidebar.slider("Neurones cachÃ©s", 50, 200, 100)
    learning_rate = st.sidebar.selectbox("Taux d'apprentissage", [0.001, 0.01, 0.1])

# -------------------------------
# CHARGEMENT DES DONNÃ‰ES
# -------------------------------
with st.spinner("ğŸ“ Chargement des donnÃ©es..."):
    X, y = charger_donnees(DATA_DIR)

if len(X) == 0:
    st.error("âŒ Aucune donnÃ©e chargÃ©e! VÃ©rifiez le dossier de donnÃ©es.")
    st.stop()

st.success(f"âœ… {len(X)} images chargÃ©es â€“ {len(np.unique(y))} classes dÃ©tectÃ©es")

# Affichage des statistiques
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Images totales", len(X))
with col2:
    st.metric("Nombre de classes", len(np.unique(y)))
with col3:
    st.metric("Dimensions par image", f"{X.shape[1]} features")

# -------------------------------
# PRÃ‰PARATION DES DONNÃ‰ES
# -------------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA
n_components_pca = min(100, X_scaled.shape[0], X_scaled.shape[1])
pca = PCA(n_components=n_components_pca)
X_pca = pca.fit_transform(X_scaled)

# LDA
n_components_lda = min(len(np.unique(y)) - 1, 30, X_pca.shape[0], X_pca.shape[1])
if n_components_lda > 0:
    lda = LDA(n_components=n_components_lda)
    X_lda = lda.fit_transform(X_pca, y)
else:
    st.error("âŒ Pas assez de classes pour LDA!")
    st.stop()

# Split donnÃ©es
X_train, X_test, y_train, y_test = train_test_split(
    X_lda, y, test_size=0.2, stratify=y, random_state=42
)

# -------------------------------
# ENTRAÃNEMENT DU MODÃˆLE
# -------------------------------
st.header("ğŸ¯ EntraÃ®nement du modÃ¨le")

if model_choice == "Random Forest":
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42
    )
    model_name = "Random Forest"
    
elif model_choice == "SVM":
    model = SVC(
        kernel=kernel_type,
        C=C_value,
        probability=True,
        random_state=42
    )
    model_name = "SVM"
    
else:  # MLP
    model = MLPClassifier(
        hidden_layer_sizes=(hidden_layers,),
        learning_rate_init=learning_rate,
        random_state=42,
        max_iter=500
    )
    model_name = "MLP Neural Network"

with st.spinner(f"â³ EntraÃ®nement du {model_name}..."):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test) if hasattr(model, "predict_proba") else None

st.success(f"âœ… {model_name} entraÃ®nÃ© avec succÃ¨s!")

# -------------------------------
# Ã‰VALUATION
# -------------------------------
st.header("ğŸ“Š Ã‰valuation des performances")

accuracy = accuracy_score(y_test, y_pred) * 100
precision = precision_score(y_test, y_pred, average='weighted', zero_division=0) * 100
recall = recall_score(y_test, y_pred, average='weighted', zero_division=0) * 100
f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0) * 100

# MÃ©triques en colonnes
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Exactitude", f"{accuracy:.2f}%")
with col2:
    st.metric("PrÃ©cision", f"{precision:.2f}%")
with col3:
    st.metric("Rappel", f"{recall:.2f}%")
with col4:
    st.metric("F1-Score", f"{f1:.2f}%")

# -------------------------------
# MATRICE DE CONFUSION
# -------------------------------
st.subheader("ğŸ¯ Matrice de confusion")
fig_cm, ax = plt.subplots(figsize=(10, 8))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
ax.set_xlabel('PrÃ©dit')
ax.set_ylabel('RÃ©el')
ax.set_title(f'Matrice de Confusion - {model_name}')
st.pyplot(fig_cm)

# -------------------------------
# VISUALISATIONS
# -------------------------------
st.header("ğŸ“ˆ Visualisations")

tab1, tab2, tab3 = st.tabs(["PCA vs LDA", "Variance PCA", "Features importantes"])

with tab1:
    fig_vis, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap="viridis", alpha=0.6)
    ax1.set_title("Projection PCA (2D)")
    ax1.set_xlabel("Composante 1")
    ax1.set_ylabel("Composante 2")
    plt.colorbar(scatter1, ax=ax1)
    
    scatter2 = ax2.scatter(X_lda[:, 0], X_lda[:, 1], c=y, cmap="viridis", alpha=0.6)
    ax2.set_title("Projection LDA (2D)")
    ax2.set_xlabel("Composante 1")
    ax2.set_ylabel("Composante 2")
    plt.colorbar(scatter2, ax=ax2)
    
    st.pyplot(fig_vis)

with tab2:
    fig_var, ax = plt.subplots(figsize=(10, 4))
    ax.plot(np.cumsum(pca.explained_variance_ratio_), linewidth=2)
    ax.set_title("Variance cumulÃ©e expliquÃ©e par PCA")
    ax.set_xlabel("Nombre de composantes")
    ax.set_ylabel("Variance cumulÃ©e")
    ax.grid(True, alpha=0.3)
    st.pyplot(fig_var)

with tab3:
    if model_choice == "Random Forest":
        fig_imp, ax = plt.subplots(figsize=(10, 6))
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1][:20]  # Top 20 features
        
        ax.bar(range(len(indices)), importances[indices])
        ax.set_title("Top 20 des features les plus importantes (Random Forest)")
        ax.set_xlabel("Index de la feature")
        ax.set_ylabel("Importance")
        st.pyplot(fig_imp)
    else:
        st.info("ğŸ“Š L'analyse des features importantes est disponible pour Random Forest")

# -------------------------------
# PRÃ‰DICTION EN TEMPS RÃ‰EL
# -------------------------------
st.header("ğŸ¯ PrÃ©diction sur nouvelles images")

uploaded_files = st.file_uploader(
    "TÃ©lÃ©chargez des images pour tester le modÃ¨le",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True,
    key="predictor"
)

def predict_image(img):
    """PrÃ©dit la classe d'une image"""
    face = extraire_visage(img)
    if face is None:
        return None, None, None
    
    flat = face.flatten()
    scaled = scaler.transform([flat])
    pca_feat = pca.transform(scaled)
    lda_feat = lda.transform(pca_feat)
    
    pred_class = model.predict(lda_feat)[0]
    
    if hasattr(model, 'predict_proba'):
        confidence = np.max(model.predict_proba(lda_feat)) * 100
    else:
        confidence = 100.0  # Si pas de probabilitÃ©s, on met 100%
    
    return pred_class, confidence, face

def trouver_images_similaires(person_id, max_images=6):
    """Trouve des images similaires de la mÃªme personne"""
    similar_images = []
    for file in os.listdir(DATA_DIR):
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            try:
                # Extraction ID depuis le nom de fichier
                if '-' in file:
                    file_person_id = int(file.split("-")[0])
                else:
                    file_person_id = int(''.join(filter(str.isdigit, file)) or 1)
                
                if file_person_id == person_id + 1:  # +1 car nos labels commencent Ã  0
                    img_path = os.path.join(DATA_DIR, file)
                    img = cv2.imread(img_path)
                    if img is not None:
                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        similar_images.append(img_rgb)
                        if len(similar_images) >= max_images:
                            break
            except:
                continue
    return similar_images

if uploaded_files:
    for uploaded_file in uploaded_files:
        st.markdown("---")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            # Affichage image originale
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            st.image(img_rgb, caption="Image originale", use_column_width=True)
            
            # RÃ©initialiser le pointeur du fichier pour la prÃ©diction
            uploaded_file.seek(0)
        
        with col2:
            # PrÃ©diction
            pred_class, confidence, face = predict_image(img)
            
            if pred_class is not None:
                st.success(f"âœ… **Personne identifiÃ©e : {pred_class + 1}**")
                st.metric("Confiance", f"{confidence:.2f}%")
                
                if face is not None:
                    st.image(face, caption="Visage dÃ©tectÃ© et prÃ©traitÃ©", width=200)
                
                # Affichage images similaires
                st.subheader("ğŸ” Images similaires de cette personne")
                similar_images = trouver_images_similaires(pred_class)
                
                if similar_images:
                    cols = st.columns(3)
                    for idx, sim_img in enumerate(similar_images[:6]):
                        with cols[idx % 3]:
                            st.image(sim_img, width=120)
                else:
                    st.info("Aucune autre image trouvÃ©e pour cette personne")
                    
            else:
                st.error("âŒ Aucun visage dÃ©tectÃ© dans l'image")

# -------------------------------
# SAUVEGARDE DU MODÃˆLE
# -------------------------------
st.sidebar.header("ğŸ’¾ Sauvegarde")

if st.sidebar.button("ğŸ’¾ Sauvegarder le modÃ¨le"):
    try:
        model_data = {
            'model': model,
            'scaler': scaler,
            'pca': pca,
            'lda': lda,
            'image_size': IMAGE_SIZE
        }
        joblib.dump(model_data, 'modele_reconnaissance_faciale.pkl')
        st.sidebar.success("âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s!")
    except Exception as e:
        st.sidebar.error(f"âŒ Erreur sauvegarde: {e}")

# -------------------------------
# INFORMATIONS SYSTÃˆME
# -------------------------------
with st.sidebar:
    st.header("â„¹ï¸ Informations")
    st.write(f"ğŸ“Š Images: {len(X)}")
    st.write(f"ğŸ¯ Classes: {len(np.unique(y))}")
    st.write(f"ğŸ”¢ Features: {X.shape[1]}")
    st.write(f"ğŸ§  ModÃ¨le: {model_name}")
    st.write("âœ… **TensorFlow non requis**")

# Footer
st.markdown("---")
st.markdown("*SystÃ¨me de reconnaissance faciale utilisant PCA + LDA + Machine Learning*")